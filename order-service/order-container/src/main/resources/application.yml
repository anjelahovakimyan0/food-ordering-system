spring:
    application:
        name: order-container
    jpa:
        open-in-view: false # PersistenceContext will not stayed open if there is no request to the db, this field is true by default and it will db connection opened for a long time which decreases the performance when it's opened
        show-sql: true # sql statement-ները, որոնք autogenerated են հիմի console-ում logged կերևան
        database-platform: org.hibernate.dialect.PostgreSQL9Dialect
        properties:
            hibernate:
                dialect: org.hibernate.dialect.PostgreSQL9Dialect # postgres 9 պիտ գործածենք
    datasource:
        url: jdbc:postgresql://localhost:5432/postgres?currentSchema=order&binaryTransfer=true&reWriteBatchedInserts=true&stringtype=unspecified
        username: postgres
        password: admin
        driver-class-name: org.postgresql.Driver
        platform: postgres
        schema: classpath:init-schema.sql
        initialization-mode: always # init-schema.sql file will run each time, when running spring boot application

server:
    port: 8181

logging:
    level:
      am.itspace: DEBUG

order-service:
    payment-request-topic-name: payment-request
    payment-response-topic-name: payment-response
    restaurant-approval-request-topic-name: restaurant-approval-request
    restaurant-approval-response-topic-name: restaurant-approval-response

kafka-config:
    bootstrap-servers: localhost:19092, localhost:29092, localhost:39092 # broker addresses in kafka cluster
    schema-registry-url-key: schema.registry.url
    schema-registry-url: http://localhost:8081
    num-of-partitions: 3
    replication-factor: 3

kafka-producer-config:
    key-serializer-class: org.apache.kafka.common.serialization.StringSerializer #produces key using StringSerializer, orderId will be represented as String in kafka
    value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer #produces value serializing with KafkaAvroSerializer
    compression-type: snappy #compress data by snappy compressing type when producing, for high performance
    acks: all #producer will wait for kafka broker confirmation that producing succeed, to compete producing operation in the code, without acks it will lead to non resilient system. acks: all - means that we will wait for confirmation on all producing operations
    batch-size: 16384 #16 kb for batch-size what is the default value, producer produce data to kafka in batches
    batch-size-boost-factor: 100 #to increase batch-size
    linger-ms: 5 #set delay on ptoducer before sending data, with the delay it will increase the batch-size and it will be a true put into the kafka broker
    request-timeout-ms: 60000 #timeout for kafka broker callback. If no response comes from kafka broker, we will wait 60000 and throw timeout error
    retry-count: 5 #in case of error from the producer side it will be retried 5 times

kafka-consumer-config:
    key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
    payment-consumer-group-id: payment-topic-consumer #this ensures that consumer will not begin topic reading from the begginnig each time, it will consume from the last consumed data, this is reached by offset, and offset is matched with consumer-group using the unique id
    restaurant-approval-consumer-group-id: restaurant-approval-topic-consumer # group-ids will be specific ids, not random ids, cause in case of random ids it will consume data each time from the beginning
    auto-offset-reset: earliest #if there is no offset set yet, it will consume from the biginning og the partition. We can set as latest and it will not consume for the first time from the beginning, but will only consume new data - offset will reset for the lateset
    specific-avro-reader-key: specific.avro.reader
    specific-avro-reader: true
    batch-listener: true #instead of consuming the data one by one, it will consume it by batches
    auto-startup: true #kafka consumer will start consuming automatically, no one is necessary to call consumer to start working, if this property set as false kafka listener will not start automatically
    concurrency-level: 3 #Քանի որ ունենք 3 kafka brokers which are consumed with 3 consumers ու now we have 3 threads with this property and we can consume data concurrently
    session-timeout-ms: 10000 #if consumer group-ում consumer-ը ինչ-որ բան չարավ ամենասկզբում էս ժամանակամիջոցում, ապա consumer-ին կհամարե dead ու կջնջե consumer group-ից
    heartbeat-interval-ms: 3000 # 3 վայրկյանը մեկ պիտ consumer-ը consumer group-ում ակտիվ ըլլա, որ ջնջման ենթակա չըլլա, ու աս property-ներով 3 անգամ ասպես փորձելուց հետո նոր consumer-ին կջնջե, էս դեպքում 3 անգամ, որտև session-timeout-ի մեկ երրորդը կկազմե
    max-poll-interval-ms: 300000 # data processing time, որտև data processing time-ը կռնա երկար ըլլա կախված consume էղնող data-ի ծավալից ու կարողա էդ ընթացքում նշվի consumer-ը dead, որպեսզի consuming-ի ընթացքում as dead mark չըլլա, աս property-ն կդնենք
    max-poll-records: 500 # at a time 500 objecct կռնա consume էնե մեկից
    max-partition-fetch-bytes-default: 1048576 # այսքան բայթ կռնա մեկից consume ըլլա, ոչ ավել
    max-partition-fetch-bytes-boost-factor: 1
    poll-timeout-ms: 150 #if consumer wants to fetch data but there is no data, it will wait some time lock the client code, այսինքն, եթե data ես consume անում անում անում ու ըհըն պրծավ, էլ մեր consumer-ը 150 միլիվայրկյանից հետո չի սպասե, ըդիկ լավ է, որ մեր կոդը locked չմնա՝ ազատվի, threads will not be locked, they can do anything important than beeing locked․ Շատ կարճ էլ պետք չէ դնել էս թիվը, որ ղարյա կամ անղարյա չպակվի/բացվի ու cpu-ն ըդտեղ կտուժե, որտև անղարյա locked-ը թազուց պիտ thread բացե, անկապ ու անիմաստ կեղնի, եթե անկապ տեղը փակե, ու մյամ էլ էլի բացե, շտը թող չփակե
